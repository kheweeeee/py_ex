{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a654eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests)\n",
      "  Downloading charset_normalizer-3.4.4-cp314-cp314-win_amd64.whl.metadata (38 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Downloading urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Downloading certifi-2026.2.25-py3-none-any.whl.metadata (2.5 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp314-cp314-win_amd64.whl (107 kB)\n",
      "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading urllib3-2.6.3-py3-none-any.whl (131 kB)\n",
      "Downloading certifi-2026.2.25-py3-none-any.whl (153 kB)\n",
      "Installing collected packages: urllib3, idna, charset_normalizer, certifi, requests\n",
      "\n",
      "   ---------------------------------------- 0/5 [urllib3]\n",
      "   ---------------------------------------- 0/5 [urllib3]\n",
      "   ---------------------------------------- 0/5 [urllib3]\n",
      "   -------- ------------------------------- 1/5 [idna]\n",
      "   ---------------- ----------------------- 2/5 [charset_normalizer]\n",
      "   ---------------- ----------------------- 2/5 [charset_normalizer]\n",
      "   -------------------------------- ------- 4/5 [requests]\n",
      "   -------------------------------- ------- 4/5 [requests]\n",
      "   ---------------------------------------- 5/5 [requests]\n",
      "\n",
      "Successfully installed certifi-2026.2.25 charset_normalizer-3.4.4 idna-3.11 requests-2.32.5 urllib3-2.6.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eeb8e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
      "Collecting beautifulsoup4 (from bs4)\n",
      "  Downloading beautifulsoup4-4.14.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting soupsieve>=1.6.1 (from beautifulsoup4->bs4)\n",
      "  Downloading soupsieve-2.8.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typing-extensions>=4.0.0 (from beautifulsoup4->bs4)\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Downloading beautifulsoup4-4.14.3-py3-none-any.whl (107 kB)\n",
      "Downloading soupsieve-2.8.3-py3-none-any.whl (37 kB)\n",
      "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Installing collected packages: typing-extensions, soupsieve, beautifulsoup4, bs4\n",
      "\n",
      "   ---------- ----------------------------- 1/4 [soupsieve]\n",
      "   -------------------- ------------------- 2/4 [beautifulsoup4]\n",
      "   -------------------- ------------------- 2/4 [beautifulsoup4]\n",
      "   ---------------------------------------- 4/4 [bs4]\n",
      "\n",
      "Successfully installed beautifulsoup4-4.14.3 bs4-0.0.2 soupsieve-2.8.3 typing-extensions-4.15.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b909a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "# requests 모듈 ==> 웹 페이지를 요청하고 응답 데이터를 받을 수 있음\n",
    "import requests as req\n",
    "from bs4 import BeautifulSoup # 파이썬이 Html을 읽을 수 있도록 도와주는 번역기느낌\n",
    "\n",
    "\n",
    "response = req.get(\"https://www.naver.com/\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5c6722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== a태그 리스트 ==\n",
      "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>, <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>, <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n",
      "== a태그 리스트중 첫 번째 ==\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>\n",
      "== a태그 리스트 중 첫 번째 텍스트 ==\n",
      "Elsie\n",
      "== a태그 리스트에 있는 텍스트모두 출력 ==\n",
      "Elsie\n",
      "Lacie\n",
      "Tillie\n",
      "== a태그 리스트에 있는 링크 모두 출력 ==\n",
      "http://example.com/elsie\n",
      "http://example.com/lacie\n",
      "http://example.com/tillie\n"
     ]
    }
   ],
   "source": [
    "html_doc = \"\"\"<html><head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
    "\n",
    "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "and they lived at the bottom of a well.</p>\n",
    "\n",
    "<p class=\"story\">...</p>\n",
    "\"\"\"\n",
    "from bs4 import BeautifulSoup\n",
    "# print(html_doc)\n",
    "soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "# soup를 이용해서 html_doc 문자열 파싱, 그 내용을 soup 변수에 대입\n",
    "\n",
    "a_list = soup.select('a')\n",
    "print(\"== a태그 리스트 ==\")\n",
    "print(a_list)\n",
    "\n",
    "print(\"== a태그 리스트중 첫 번째 ==\")\n",
    "print(a_list[0])\n",
    "\n",
    "print(\"== a태그 리스트 중 첫 번째 텍스트 ==\")\n",
    "print(a_list[0].text)\n",
    "\n",
    "print(\"== a태그 리스트에 있는 텍스트모두 출력 ==\")\n",
    "for a in a_list:\n",
    "    print(a.text)\n",
    "\n",
    "print(\"== a태그 리스트에 있는 텍스트 모두 출력 ==\")\n",
    "for link in a_list:\n",
    "    print(link['href']) # 속성을 선택할 땐 대괄호\n",
    "\n",
    "\n",
    "# html 선택 방법 (css선택자)\n",
    "# 1. 태그 선택\n",
    "# 2. 후손 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18b7c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# requests 모듈 => 웹 페이지를 요청하고 응답 데이터를 받을 수 있음\n",
    "import requests as req\n",
    "from bs4 import BeautifulSoup # BeautifulSoup => html 해석기\n",
    "\n",
    "# 요청 시 오류 났을 때 아래 문구를 입력해주세요.\n",
    "request_headers = {'User-Agent': ('Mozilla/5.0 (Windows NT 10.0;Win64; x64)AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98Safari/537.36'), }\n",
    "\n",
    "response = req.get(\"https://www.naver.com/\", request_headers)\n",
    "# print(response)\n",
    "\n",
    "html_doc = \"\"\"<html><head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
    "\n",
    "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "and they lived at the bottom of a well.</p>\n",
    "\n",
    "<p class=\"story\">...</p>\n",
    "\"\"\"\n",
    "\n",
    "# print(html_doc)\n",
    "\n",
    "soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "# soup을 이용해서 html_doc 문자열 파싱, 그 내용을 soup 변수에 대입\n",
    "\n",
    "a_list = soup.select('a')\n",
    "\n",
    "print(\"== a태그들 리스트 ==\")\n",
    "print(a_list)\n",
    "\n",
    "print(\"== a태그 리스트 중 첫 번째 ==\")\n",
    "print(a_list[0])\n",
    "\n",
    "print(\"== a태그 리스트 중 첫 번째 텍스트 ==\")\n",
    "print(a_list[0].text)\n",
    "\n",
    "print(\"== a태그 리스트 중 첫 번째 링크 ==\")\n",
    "print(a_list[0]['href']) # 속성을 선택할 땐 대괄호\n",
    "\n",
    "print(\"== a태그 리스트에 있는 텍스트 모두 출력 ==\")\n",
    "for a in a_list:\n",
    "    print(a.text)\n",
    "\n",
    "print(\"== a태그 리스트에 있는 링크 모두 출력 ==\")\n",
    "for link in a_list:\n",
    "    print(link['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2079ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "“과기부·KISA에 수사권 부여”… 與 조인철 의원,  ‘해킹 특사경 법’ 발의\n",
      "== 반복문으로 텍스트 출력 ==\n",
      "“과기부·KISA에 수사권 부여”… 與 조인철 의원,  ‘해킹 특사경 법’ 발의\n",
      "국힘 17% 지지율 쇼크, 조선일보 \"터무니없는 '윤어게인'당 됐다\"\n",
      "Korea, UAE agree to pursue $65b in joint projects: Cheong Wa Dae\n",
      "상설 특검, '쿠팡 불기소 외압 의혹' 엄희준·김동희 검사 기소\n",
      "[속보] 상설특검, '쿠팡 수사 방해' 엄희준·김동희 검사 기소\n",
      "李대통령 \"전북 삼중소외 안타까워…균형발전 죽을힘 다하는 중\"\n",
      "현대차그룹, 새만금에 9조 투자…'피지컬 AI' 거점으로\n",
      "[속보]사퇴 표명 법원행정처장 \"사법개혁, 국민 이익되는 방향이어야\"\n",
      "[티타임] 4.9조 털고 떠나는 외국인… 낙폭 축소 코스피, 6280선\n",
      "‘밥 한공기 300원’ 당신의 생각은?…농협 “소비자 절반, 저렴 인식”\n",
      "정부, 구글 고정밀지도 국외반출 허가…국내 서버 가공·보안 조건부 승인\n",
      "김재섭 \"정원오, 대규모 사업 수주한 성동구 쓰레기 업체들로부터 최대치 후원받아\"\n",
      "법원행정처장 사의 표명…\"사법개혁 논의 국민 이익돼야\"\n",
      "\"이 정도로 잘 팔릴 줄이야\"...한국서 부는 '중국 전기차' 열풍\n",
      "현생 인류 여성과 만난 네안데르탈인 남성…X염색체에 네안데르탈인 DNA가 적은 이유\n",
      "[속보] 코스닥 장중 1200 돌파...사상 최고치 경신\n",
      "[속보] 코스닥 장중 1200 돌파…사상 최고치 경신\n",
      "[단독] 인사 유출 홍역 치른 삼성바이오, 이번엔 “주 4.5일·ADC 수당” 노사 갈등 뇌관\n",
      "\"한국 아니었네\"…中관광객, 춘절에 日 대신 많이 간 곳은\n",
      "[속보]국힘, ‘신천지 당원가입 의혹’ 당사 압수수색에 “野탄압·독재”\n",
      "구글, 메타에 수십억달러 규모 ‘AI칩 임대’…엔비디아 아성에 도전장\n",
      "80년 해직언론인들 \"12·3 저지한 5·18정신, 헌법전문 넣어야\"\n",
      "[디깅노트] 대기업에 쏠린 여신…중복규제에 막힌 생산적 금융\n",
      "법원 난입 그날 \"자고 있었다\"는 전광훈…재판부 \"범죄 불명확\"\n",
      "금 세공 맡겼더니 잠적…'28억 사기 혐의' 금은방 업주 송치\n",
      "李 대통령 “투기용 1주택자도 매각 유리한 상황 만들 것\"\n",
      "정부, 구글에 고정밀지도 국외 반출 허가…군사·보안시설 노출은 안돼\n",
      "색동원 시설장, 장애인 성폭력 혐의로 검찰 송치\n",
      "모건스탠리 \"코스피 급등? 상반기 7500피\"…강세 시나리오 보니\n",
      "\"수익률 96% 대박\"…삼성전자 안 팔고 버틴 개미들 신났다\n",
      "예상보다 거친 표현, 더는 남쪽에 기댈 필요 없다는 김정은의 자신감\n",
      "이 대통령 64%… ‘경제’가 밀고 ‘질서 인식’이 받쳤다, 60%대  이어질까\n",
      "박영재 법원행정처장 사의 표명… 與 ‘사법 3법’ 강행 후 첫 법원 고위직 사임\n",
      "간결히 정리한 시행규칙 세부내용 [25년 세법 후속 시행규칙]\n",
      "국민연금 지난해 231조 벌었다…국장 수익률 82.4% ‘역대급’\n",
      "Kospi topping 6,000 masks K-shaped divide in economy, economists warn\n",
      "정부, 구글 1:5000 지도 국외 반출 허가…軍시설 가림 등 조건부 승인(상보)\n",
      "“다른 사람 아냐?” 윤진이, 살 쭉쭉 빠져 45kg 달성…뭐 했길래?\n",
      "\"대통령님, 촉법소년 나이보다 중요한 게 있습니다\" 1호 학폭 전문 변호사의 제안\n",
      "정부, 구글에 고정밀 지도 국외 반출 조건부 허가\n",
      "펜션 베란다 욕조 안에서 50대 남녀 숨진 채 발견…경찰 조사 중\n",
      "[속보] 정부, 구글에 ‘내비게이션 지도’ 반출 허용…“보안 문제 없는 정보만 반출”\n",
      "민주당, 강원도지사 후보에 우상호 단수 공천... 전국 1호 공천 확정\n",
      "李대통령 \"투기용 1주택자도 매각 유리하도록 정책수단 총동원\"\n",
      "박영재 법원행정처장 사의… 與 '사법개혁 3법' 강행에 배수진\n",
      "김진균 예비후보 \"탁월성 교육으로 잠재 능력 극대화\"\n",
      "[속보] 정부, 구글에 고정밀 지도 국외 반출 조건부 허가\n",
      "[속보] 박영재 법원행정처장직 사의…사법 3법 추진에 반발\n",
      "정부, 구글에 1대 5천 고정밀지도 국외 반출 조건부 허가\n",
      "尹 '1심 무기징역'에 항소한 내란특검…\"늦어도 11월9일에 계엄 결심\"\n",
      "암 투병해보니 “힘내”란 말 대신 “버텨”\n",
      "\"시장 붕괴 가능성\" \"과열 구간\" 경고에도...개미들은 \"떨어진다, 줍자\"\n",
      "고정밀 지도 해외로…구글에 보안 조건 달고 허가\n",
      "[단독] 김용관 삼성전자 사장 “국가산단 속도 더 내야…1분기 실적 좋은 결과 있을 것”\n",
      "[속보] 정부, 구글에 지도 국외 반출 조건부 허가\n",
      "국토부, 구글 고정밀 지도 반출 '조건부 허가'\n",
      "“진짜 강심장이네” 코스피 3배 레버리지 사려고 줄 섰다…99%나 급등 [투자360]\n",
      "[속보] 50대 남녀, 펜션 욕조 속 반쯤 잠겨 숨진 채 발견…경찰 조사 착수\n",
      "7000자 보고서가 쏘아 올린 ‘AI 파괴론’···미래는 디스토피아일까\n",
      "박영재 대법관, 법원행정처장직 사의…사법개혁 반발 고조\n",
      "대관 취소한 김동연, '나 두려워?' 전한길에 \"제정신인가? 거의 미친 수준\"\n",
      "홍준표 “내 살 집 하나면 족해”…李 부동산 규제에 공감\n",
      "‘내란’ 판결문 실명 복원… “역사는 익명 뒤에 숨을 수 없다”\n",
      "전광훈, 첫 재판서 “서부지법 사태 때 자고 있었다”···변호인 “성한 곳 없어” 보석 신청\n",
      "박영재 법원행정처장 사의...'사법개혁' 법안 상정 줄줄이\n",
      "극우시위 반대하자 경찰이 후추스프레이... 남일이 아니다\n",
      "내란특검 \"윤석열, 늦어도 11월9일 계엄 결정…우발적 조치 아냐\"\n",
      "“금세 홀쭉해졌다” 성시경, 한 달간 ‘이것’ 먹으니 빠졌다는데… 뭐지?\n",
      "정부, '1대 5000 축척' 고정밀지도 구글 반출 허가\n",
      "박영재 법원행정처장 사의 표명…\"사법 개편 국민에 이익 돼야\"\n",
      "박영재 법원행정처장 사의... 與 ‘사법 3법’ 강행에 반발\n",
      "한동훈, 대구 서문시장 도착···수천 명 인파 몰려 '인산인해'\n",
      "정부, 구글에 1대 5천 축척 지도 반출 허가 결정\n",
      "\"전북이 전력 식민지냐\".. 송전탑 대책위, 이재명 대통령에 용인 산단 재검토 촉구\n",
      "미래에셋 ‘타이거’, ETF 수익률 전체 1·2위 차지\n",
      "경북, 시골 이장님들이 제일 골치 썩는 이 문제 [우리 동네 지선 의제]\n",
      "美 연준 의장 인선 후 금리·달러·자금 흐름 엇갈리는 이유\n",
      "[단독]상설특검, 엄희준·김동희 기소…‘쿠팡’ 압력행사 혐의\n",
      "칠레 최초의 국립공원이자, 파타고니아 관문 [세계의 국립공원]\n",
      "\"국민과 사법부 위해\"…박영재 법원행정처장, 사의 표명\n",
      "[속보] 박영재 법원행정처장, ‘사법개혁’ 강행에 처장직 사퇴 표명\n",
      "삼전·하닉에 결혼자금 3억 몰빵 투자한 공무원…결말은?\n"
     ]
    }
   ],
   "source": [
    "response = req.get(\"http://news.naver.com/\")\n",
    "print(response)\n",
    "\n",
    "# html 문자열 파싱\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "content = soup.select('.cnf_news_title')\n",
    "print(content[0].text)\n",
    "\n",
    "print(\"== 반복문으로 텍스트 출력 ==\")\n",
    "for c in content:\n",
    "    print(c.text)\n",
    "\n",
    "content2 = soup.select('.cnf_news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea18bf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class=\"sds-comps-image-after-content\n",
    "\n",
    "\n",
    "imgs = soup.select('.cnf_news_thumb img')\n",
    "\n",
    "for "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
